{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 4주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunSunouk/munsunouk..github.io/blob/master/4%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ":1943년 워랜 맥컬록과 월터 피츠는 처음으로 간소화된 뇌의 뉴런개념을 발표하였다. 여기서 이들은 신경세포를 이진 출력을 내는 간단한 논리회로로 표현했으며, 수상돌기에 여러신호가 도착하면 세포체에 합쳐지고 합쳐진 신호가 특정 임계값을 넘으면 출력신호가 생성되고  축삭돌기를 이용하여 전달됩니다.\n",
        "[reference](https://books.google.co.kr/books?id=eEWhDwAAQBAJ&pg=PT68&lpg=PT68&dq=MCP+%EB%89%B4%EB%9F%B0&source=bl&ots=wpn1bfGyK4&sig=ACfU3U1_vKBaTnHNdQoULlkWi3KtOeqx-A&hl=ko&sa=X&ved=2ahUKEwjy4cvylvzpAhW9L6YKHVVrA2AQ6AEwCHoECAgQAQ#v=onepage&q=MCP%20%EB%89%B4%EB%9F%B0&f=false)\n",
        "\n",
        "### 퍼셉트론\n",
        ":1957년 프랭크 로젠 블랫은 MCP 뉴런 모델을 기반으로 퍼셉트론 규칙을 만들었다.\n",
        "퍼셉트론 규칙은 자동으로 최적의 가중치를 학습하는  알고리즘을 제안하였다.\n",
        "지도학습과 분류개념으로 말하자면  이 알고리즘으로 샘플이 한 클래스에 속하는지 아닌지를 예측할수있다.\n",
        "[reference](https://books.google.co.kr/books?id=eEWhDwAAQBAJ&pg=PT68&lpg=PT68&dq=MCP+%EB%89%B4%EB%9F%B0&source=bl&ots=wpn1bfGyK4&sig=ACfU3U1_vKBaTnHNdQoULlkWi3KtOeqx-A&hl=ko&sa=X&ved=2ahUKEwjy4cvylvzpAhW9L6YKHVVrA2AQ6AEwCHoECAgQAQ#v=onepage&q=MCP%20%EB%89%B4%EB%9F%B0&f=false)\n",
        "\n",
        "### 역전파\n",
        ":기대값과 출력값이 다를경우 가중치 업데이트 오차를 각각의 가중치에 넣어줘서 기대값과 출력값이 같도록 하는것이다\n",
        "\n",
        "![alt text](https://wikidocs.net/images/page/37406/nn3_final.PNG)\n",
        "순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트해갑니다. 출력층 바로 이전의 은닉층을 N층이라고 하였을 때, 출력층과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계, 그리고 N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계를 역전파 2단계라고 해봅시다.\n",
        "\n",
        "![alt text](https://wikidocs.net/images/page/37406/nn4.PNG)\n",
        "1단계를 완료하였다면 이제 입력층 방향으로 이동하며 다시 계산을 이어갑니다. 위의 그림에서 빨간색 화살표는 순전파의 정반대 방향인 역전파의 방향을 보여줍니다. 현재 인공 신경망은 은닉층이 1개밖에 없으므로 이번 단계가 마지막 단계입니다. 하지만 은닉층이 더 많은 경우라면 입력층 방향으로 한 단계씩 계속해서 계산해가야 합니다.\n",
        "[reference](https://wikidocs.net/37406)\n",
        "### 강화학습\n",
        ": 기계 학습의 한 영역이다. 행동심리학에서 영감을 받았으며, 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법이다. 이러한 문제는 매우 포괄적이기 때문에 게임 이론, 제어이론, 운용 과학, 정보 이론, 시뮬레이션 기반 최적화, 다중 에이전트 시스템, 떼 지능, 통계학, 유전 알고리즘 등의 분야에서도 연구된다. 운용 과학과 제어 이론에서 강화 학습이 연구되는 분야는 \"근사 동적 계획법\"이라고 불린다. 또한 최적화 제어 이론에서도 유사한 문제를 연구하지만, 대부분의 연구가 최적해의 존재와 특성에 초점을 맞춘다는 점에서 학습과 근사의 측면에서 접근하는 강화 학습과는 다르다. 경제학과 게임 이론 분야에서 강화 학습은 어떻게 제한된 합리성 하에서 평형이 일어날 수 있는지를 설명하는 데에 사용되기도 한다.\n",
        "[reference](https://ko.wikipedia.org/wiki/%EA%B0%95%ED%99%94_%ED%95%99%EC%8A%B5)\n",
        "\n",
        "### 과적합\n",
        ":과적합(overfitting)은 기계 학습(machine learning)에서 학습 데이타를 과하게 학습(overfitting)하는 것을 뜻한다. 일반적으로 학습 데이타는 실제 데이타의 부분 집합이므로 학습데이타에 대해서는 오차가 감소하지만 실제 데이타에 대해서는 오차가 증가하게 된다.\n",
        "\n",
        "일반적으로 학습 데이타는 실제 데이타의 부분집합이며, 실제 데이타를 모두 수집하는 것은 불가능하다.\n",
        "만약 실제 데이타를 모두 수집하여도 모든 데이타를 학습 시키기 위한 시간이 측정 불가능한 수준으로 증가 할 수 있다.\n",
        "학습 데이타만 가지고 실제 데이타의 오차가 증가하는 지점을 예측하는 것은 매우 어렵거나 불가능하다.\n",
        "[reference](https://ko.wikipedia.org/wiki/%EA%B3%BC%EC%A0%81%ED%95%A9)\n",
        "\n",
        "### 차원의 저주\n",
        ": 저주 현상은 수치 분석 , 샘플링 , 조합 , 기계 학습 , 데이터 마이닝 및 데이터베이스 와 같은 영역에서 발생 합니다 . 이러한 문제의 일반적인 주제는 차원이 증가 할 때 공간 의 양 이 너무 빨리 증가하여 사용 가능한 데이터가 희박 해지는 것입니다. 이 희소성은 통계적 유의성 이 필요한 모든 방법에 문제가 있습니다.. 통계적으로 건전하고 신뢰할 수있는 결과를 얻기 위해 결과를 지원하는 데 필요한 데이터 양이 종종 차원에 따라 기하 급수적으로 증가합니다. 또한 데이터를 구성하고 검색하는 경우 개체가 비슷한 속성을 가진 그룹을 형성하는 영역을 감지하는 데 종종 의존합니다. 그러나 차원이 높은 데이터에서는 모든 개체가 여러면에서 희박하고 유사하지 않은 것처럼 보이므로 일반적인 데이터 구성 전략이 효율적이지 않습니다.\n",
        "[reference](https://en.wikipedia.org/wiki/Curse_of_dimensionality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HVtNrGVYKpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "3c799fb7-536c-4c41-bda4-f7a78544e024"
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1],0,1)\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + math.exp(-x))\n",
        "output = sigmoid(x * w)\n",
        "print(output)\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x * w)\n",
        "  error = y - output\n",
        "  w = w + x * 0.1 * error\n",
        "  if i % 100  == 99:\n",
        "    print(\"학습횟수 :\",i, \"Error\",error, \"예측결과:\",output)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습횟수 : 99 Error -0.10010598284299604 예측결과: 0.10010598284299604\n",
            "학습횟수 : 199 Error -0.05178399422833116 예측결과: 0.05178399422833116\n",
            "학습횟수 : 299 Error -0.034590451977903586 예측결과: 0.034590451977903586\n",
            "학습횟수 : 399 Error -0.02588962752851373 예측결과: 0.02588962752851373\n",
            "학습횟수 : 499 Error -0.020658699939863617 예측결과: 0.020658699939863617\n",
            "학습횟수 : 599 Error -0.017174253993457355 예측결과: 0.017174253993457355\n",
            "학습횟수 : 699 Error -0.014689506449480992 예측결과: 0.014689506449480992\n",
            "학습횟수 : 799 Error -0.012829497265431342 예측결과: 0.012829497265431342\n",
            "학습횟수 : 899 Error -0.011385568271837804 예측결과: 0.011385568271837804\n",
            "학습횟수 : 999 Error -0.010232493309882492 예측결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.6\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    }
  ]
}